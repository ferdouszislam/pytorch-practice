{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cross_entropy_false_error.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdouszislam/pytorch-practice/blob/main/cross_entropy_false_error.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hg4u5vOI32Z"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd5IxhfIJHTS"
      },
      "source": [
        "# Cross Entropy Loss implementation taken from- <https://discuss.pytorch.org/t/how-to-write-custom-crossentropyloss/58072>\n",
        "# modified to create cross_entropy_false_error() function \n",
        "\n",
        "def log_softmax(x):\n",
        "  return x - torch.logsumexp(x,dim=1, keepdim=True)\n",
        "\n",
        "def cross_entropy(outputs, targets):\n",
        "  num_examples = targets.shape[0]\n",
        "  batch_size = outputs.shape[0]\n",
        "  outputs = log_softmax(outputs)\n",
        "  outputs = outputs[range(batch_size), targets]\n",
        "\n",
        "  return - torch.sum(outputs)/num_examples\n",
        "\n",
        "def cross_entropy_squared_false_error(outputs, targets):\n",
        "  #courtesy- \"https://ieeexplore.ieee.org/abstract/document/7727770\"\n",
        "  num_examples = targets.shape[0]\n",
        "  batch_size = outputs.shape[0]\n",
        "  outputs = log_softmax(outputs)\n",
        "  outputs = outputs[range(batch_size), targets]\n",
        "  outputs = -1 * outputs\n",
        "\n",
        "  all_zeroes = torch.zeros_like(targets)\n",
        "  all_ones = torch.ones_like(targets)\n",
        "\n",
        "  error_sum = 0.0\n",
        "\n",
        "  for curr_class in range(5):\n",
        "    label_tensor = torch.full(targets.size(), curr_class)\n",
        "    curr_class_pos_mul_tensors = torch.where(targets == label_tensor, all_ones, all_zeroes)\n",
        "    curr_class_pos_cnt = targets.eq(label_tensor).sum().item()\n",
        "    curr_class_neg_mul_tensors = torch.where(targets != label_tensor, all_ones, all_zeroes)\n",
        "    curr_class_neg_cnt = targets.ne(label_tensor).sum().item()\n",
        "\n",
        "    # print(f'class {curr_class}:\\npos count={curr_class_pos_cnt}, neg count={curr_class_neg_cnt}')\n",
        "    # print(f'pos_mul_tensor={curr_class_pos_mul_tensors}\\nneg_mul_tensor={curr_class_neg_mul_tensors}')\n",
        "\n",
        "    if curr_class_pos_cnt != 0: \n",
        "      error_sum += torch.pow(torch.sum(outputs*curr_class_pos_mul_tensors)/curr_class_pos_cnt, 2)\n",
        "    if curr_class_neg_cnt != 0:\n",
        "      error_sum += torch.pow(torch.sum(outputs*curr_class_neg_mul_tensors)/curr_class_neg_cnt, 2)\n",
        "\n",
        "  return error_sum / 5"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hECco-OFm_b3"
      },
      "source": [
        "outputs = torch.tensor([[300.0, 100.0, 400.0, 100.0, 100.0],\n",
        "                        [100.0, 200.0, 300.0, 200.0, 200.0],\n",
        "                        [300.0, 100.0, 400.0, 100.0, 100.0],\n",
        "                        [50.0, 150.0, 40.0, 300.0, 200.0],\n",
        "                        [300.0, 100.0, 400.0, 100.0, 156.0],\n",
        "                        [205.0, 41.0, 400.0, 62.0, 100.0],\n",
        "                        [30.0, 15.0, 400.0, 600.0, 215.0],\n",
        "                        [300.0, 100.0, 400.0, 100.0, 520.0]], requires_grad=True)\n",
        "labels = torch.tensor([0, 1, 2, 3, 4, 0, 1, 2])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWkMebkR1E_0",
        "outputId": "25007d9d-2cf3-4959-f9f1-cfb64d4c9ec7"
      },
      "source": [
        "built_in_ce = nn.CrossEntropyLoss()\n",
        "built_in_ce(outputs, labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(168., grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTCVGX5wyG25",
        "outputId": "ddae726a-43e0-486a-ec67-17d4b3807542"
      },
      "source": [
        "cross_entropy(outputs, labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(168., grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RpNgh5kyFXn",
        "outputId": "7b8113f9-dd5a-4850-fffc-af956319717a"
      },
      "source": [
        "cross_entropy_squared_false_error(outputs, labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class 0:\n",
            "pos count=2, neg count=6\n",
            "pos_mul_tensor=tensor([1, 0, 0, 0, 0, 1, 0, 0])\n",
            "neg_mul_tensor=tensor([0, 1, 1, 1, 1, 0, 1, 1])\n",
            "class 1:\n",
            "pos count=2, neg count=6\n",
            "pos_mul_tensor=tensor([0, 1, 0, 0, 0, 0, 1, 0])\n",
            "neg_mul_tensor=tensor([1, 0, 1, 1, 1, 1, 0, 1])\n",
            "class 2:\n",
            "pos count=2, neg count=6\n",
            "pos_mul_tensor=tensor([0, 0, 1, 0, 0, 0, 0, 1])\n",
            "neg_mul_tensor=tensor([1, 1, 0, 1, 1, 1, 1, 0])\n",
            "class 3:\n",
            "pos count=1, neg count=7\n",
            "pos_mul_tensor=tensor([0, 0, 0, 1, 0, 0, 0, 0])\n",
            "neg_mul_tensor=tensor([1, 1, 1, 0, 1, 1, 1, 1])\n",
            "class 4:\n",
            "pos count=1, neg count=7\n",
            "pos_mul_tensor=tensor([0, 0, 0, 0, 1, 0, 0, 0])\n",
            "neg_mul_tensor=tensor([1, 1, 1, 1, 0, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(69600.4844, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNR1ApgSqlA_"
      },
      "source": [
        "# label_tensor = torch.full(labels.size(), 4)\n",
        "# #labels.eq(label_tensor).sum()\n",
        "\n",
        "# class4_pos_mul_tensors = torch.where(labels == label_tensor, torch.ones_like(labels), torch.zeros_like(labels))\n",
        "# class4_neg_mul_tensors = torch.where(labels != label_tensor, torch.ones_like(labels), torch.zeros_like(labels))\n",
        "\n",
        "# print(labels, class4_pos_mul_tensors, class4_neg_mul_tensors)"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}